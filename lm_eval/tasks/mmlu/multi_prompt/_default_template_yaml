dataset_path: PromptEval/MMLU_multi_prompt
dataset_name: all
task_alias: all
test_split: test
fewshot_split: dev
fewshot_config:
  sampler: first_n
  doc_to_target: answer
output_type: multiple_choice
process_docs: !function utils.process_docs
doc_to_text: "{{template}}"
doc_to_choice: ["A", "B", "C", "D"]
doc_to_target: "{{answer}}"
metric_list:
  - metric: acc
    aggregation: mean
    higher_is_better: true
metadata:
  version: 1.0
dataset_kwargs:
  trust_remote_code: true